{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepocessing Of Data(Use Same AS given on Kaggle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 593,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  "
            ]
          },
          "execution_count": 593,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from subprocess import check_call\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# Loading the data\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# Store our test passenger IDs for easy access\n",
        "PassengerId = test['PassengerId']\n",
        "\n",
        "# Showing overview of the train dataset\n",
        "train.head(3)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cleaning And Feature Extracting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 594,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy original dataset in case we need it later when digging into interesting features\n",
        "# WARNING: Beware of actually copying the dataframe instead of just referencing it\n",
        "# \"original_train = train\" will create a reference to the train variable (changes in 'train' will apply to 'original_train')\n",
        "original_train = train.copy() # Using 'copy()' allows to clone the dataset, creating a different object with the same values\n",
        "\n",
        "# Feature engineering steps taken from Sina and Anisotropic, with minor changes to avoid warnings\n",
        "full_data = [train, test]\n",
        "\n",
        "# Feature that tells whether a passenger had a cabin on the Titanic\n",
        "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
        "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
        "\n",
        "# Create new feature FamilySize as a combination of SibSp and Parch\n",
        "for dataset in full_data:\n",
        "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
        "# Create new feature IsAlone from FamilySize\n",
        "for dataset in full_data:\n",
        "    dataset['IsAlone'] = 0\n",
        "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
        "# Remove all NULLS in the Embarked column\n",
        "for dataset in full_data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
        "# Remove all NULLS in the Fare column\n",
        "for dataset in full_data:\n",
        "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
        "\n",
        "# Remove all NULLS in the Age column\n",
        "for dataset in full_data:\n",
        "    age_avg = dataset['Age'].mean()\n",
        "    age_std = dataset['Age'].std()\n",
        "    age_null_count = dataset['Age'].isnull().sum()\n",
        "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
        "    # Next line has been improved to avoid warning\n",
        "    dataset.loc[np.isnan(dataset['Age']), 'Age'] = age_null_random_list\n",
        "    dataset['Age'] = dataset['Age'].astype(int)\n",
        "\n",
        "# Define function to extract titles from passenger names\n",
        "def get_title(name):\n",
        "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "    # If the title exists, extract and return it.\n",
        "    if title_search:\n",
        "        return title_search.group(1)\n",
        "    return \"\"\n",
        "\n",
        "for dataset in full_data:\n",
        "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
        "# Group all non-common titles into one single grouping \"Rare\"\n",
        "for dataset in full_data:\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "\n",
        "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "for dataset in full_data:\n",
        "    # Mapping Sex\n",
        "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
        "    \n",
        "    # Mapping titles\n",
        "    title_mapping = {\"Mr\": 1, \"Master\": 2, \"Mrs\": 3, \"Miss\": 4, \"Rare\": 5}\n",
        "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)\n",
        "\n",
        "    # Mapping Embarked\n",
        "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "    \n",
        "    # Mapping Fare\n",
        "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
        "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
        "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
        "    \n",
        "    # Mapping Age\n",
        "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
        "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
        "    dataset.loc[ dataset['Age'] > 64, 'Age'] \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature selection: remove variables no longer containing relevant information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 595,
      "metadata": {},
      "outputs": [],
      "source": [
        "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
        "train = train.drop(drop_elements, axis = 1)\n",
        "test  = test.drop(drop_elements, axis = 1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Title VS Sex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 596,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"3\" halign=\"left\">Survived</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>count</th>\n",
              "      <th>sum</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Title</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.156673</td>\n",
              "      <td>517</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.575000</td>\n",
              "      <td>40</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.793651</td>\n",
              "      <td>126</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.702703</td>\n",
              "      <td>185</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.347826</td>\n",
              "      <td>23</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Survived           \n",
              "           mean count  sum\n",
              "Title                     \n",
              "1      0.156673   517   81\n",
              "2      0.575000    40   23\n",
              "3      0.793651   126  100\n",
              "4      0.702703   185  130\n",
              "5      0.347826    23    8"
            ]
          },
          "execution_count": 596,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train[['Title', 'Survived']].groupby(['Title'], as_index=False).agg(['mean', 'count', 'sum'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 597,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"3\" halign=\"left\">Survived</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>count</th>\n",
              "      <th>sum</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sex</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.742038</td>\n",
              "      <td>314</td>\n",
              "      <td>233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.188908</td>\n",
              "      <td>577</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived           \n",
              "         mean count  sum\n",
              "Sex                     \n",
              "0    0.742038   314  233\n",
              "1    0.188908   577  109"
            ]
          },
          "execution_count": 597,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).agg(['mean', 'count', 'sum'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 598,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"3\" halign=\"left\">Sex</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>count</th>\n",
              "      <th>sum</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Title</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Capt</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Col</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Countess</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Don</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dr</th>\n",
              "      <td>0.857143</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jonkheer</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lady</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Major</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Master</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Miss</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>182</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mlle</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mme</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mr</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>517</td>\n",
              "      <td>517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mrs</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>125</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ms</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rev</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sir</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Sex           \n",
              "              mean count  sum\n",
              "Title                        \n",
              "Capt      1.000000     1    1\n",
              "Col       1.000000     2    2\n",
              "Countess  0.000000     1    0\n",
              "Don       1.000000     1    1\n",
              "Dr        0.857143     7    6\n",
              "Jonkheer  1.000000     1    1\n",
              "Lady      0.000000     1    0\n",
              "Major     1.000000     2    2\n",
              "Master    1.000000    40   40\n",
              "Miss      0.000000   182    0\n",
              "Mlle      0.000000     2    0\n",
              "Mme       0.000000     1    0\n",
              "Mr        1.000000   517  517\n",
              "Mrs       0.000000   125    0\n",
              "Ms        0.000000     1    0\n",
              "Rev       1.000000     6    6\n",
              "Sir       1.000000     1    1"
            ]
          },
          "execution_count": 598,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "title_and_sex = original_train.copy()[['Name', 'Sex']]\n",
        "\n",
        "# Create 'Title' feature\n",
        "title_and_sex['Title'] = title_and_sex['Name'].apply(get_title)\n",
        "\n",
        "# Map 'Sex' as binary feature\n",
        "title_and_sex['Sex'] = title_and_sex['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
        "\n",
        "# Table with 'Sex' distribution grouped by 'Title'\n",
        "title_and_sex[['Title', 'Sex']].groupby(['Title'], as_index=False).agg(['mean', 'count', 'sum'])\n",
        "\n",
        "# Since Sex is a binary feature, this metrics grouped by the Title feature represent:\n",
        "    # MEAN: percentage of men\n",
        "    # COUNT: total observations\n",
        "    # SUM: number of men\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create Numpy arrays of train, test and target (Survived) dataframes to feed into our models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 599,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(418, 10)"
            ]
          },
          "execution_count": 599,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train = train['Survived']\n",
        "x_train = train.drop(['Survived'], axis=1).values \n",
        "x_test = test.values\n",
        "\n",
        "adaboost_x_train = x_train\n",
        "adaboost_x_test = x_test\n",
        "adaboost_y_train = y_train\n",
        "x_test.shape\n",
        "adaboost_x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 600,
      "metadata": {
        "id": "907iFxoriO1Y"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    \"\"\"This is the node class, having left and right children to store the value, values to be store at leaf node\"\"\"\n",
        "    def __init__(self, feature_idx=None, split=None, predicted_class=None,num_samples=None):\n",
        "        self.feature_idx = feature_idx   # index of feature used for splitting\n",
        "        self.split = split               # value of feature used for splitting\n",
        "        self.predicted_class = predicted_class   # majority class in the node\n",
        "        self.left = None                 # left child node\n",
        "        self.right = None                # right child node\n",
        "        self.is_leaf = False             # flag indicating if the node is a leaf\n",
        "        self.num_samples = num_samples\n",
        "        # self.value = None\n",
        "\n",
        "    def set_params(self, feature_idx, split): # setting the parameter \n",
        "        self.feature_idx = feature_idx\n",
        "        self.split = split\n",
        "    \n",
        "    def set_children(self, left, right): # set children of the given parent node\n",
        "        self.left = left\n",
        "        self.right = right\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 601,
      "metadata": {
        "id": "N0I_7VzDKb9d"
      },
      "outputs": [],
      "source": [
        "class DecissionTree:\n",
        "  def __init__(self, criterion, max_depth,min_samples_split,min_samples_leaf):\n",
        "    \"\"\"\n",
        "    criterion - Either misclassification rate, Gini impurity, or entropy.\n",
        "    max_depth - The maximum depth the tree should grow.\n",
        "    min_samples_split - The minimum number of samples required to split.\n",
        "    min_samples_leaf - The minimum number of samples required for a leaf node.\n",
        "    \"\"\"\n",
        "    self.criterion = criterion\n",
        "    self.max_depth= max_depth\n",
        "    self.min_samples_split = min_samples_split\n",
        "    self.min_samples_leaf = min_samples_leaf\n",
        "    self.root = None\n",
        "\n",
        "  def fit(self,X,y):\n",
        "    \"\"\"Fit method to initialize X value and y to get the no. of classes, unique classes and to build the tree\"\"\"\n",
        "    self.n_classes_ = len(np.unique(y)) # getting total no. of value\n",
        "    self.classes_ = np.unique(y) # get all unique classes\n",
        "    n_samples, self.n_features_ = X.shape\n",
        "    self.root = self.grow_decission_tree(X, y) #building the tree\n",
        "    return self\n",
        "\n",
        "  def grow_decission_tree(self,X,y,depth = 0):\n",
        "    num_samples_per_class = np.bincount(y, minlength=self.n_classes_) # geting no. of samples per class\n",
        "    predicted_class = np.argmax(num_samples_per_class) # take the predicted class\n",
        "    node = Node(predicted_class=predicted_class, num_samples=y.size) # Initialize the node\n",
        "    # True condition depth is less than max_depth and if the size of y is greater than  min samples split \n",
        "    stopping_condition = depth < self.max_depth and y.size >= self.min_samples_split \n",
        "    if stopping_condition:\n",
        "      best_gain = 0.0 # initialize the gain and criteria and best sets\n",
        "      best_criteria = None\n",
        "      best_sets = None\n",
        "      for feature_idx in range(self.n_features_): # iterating through all feature_s\n",
        "        feature_values = X[:, feature_idx] \n",
        "        possible_splits = self.split_the_data(feature_values) #getting best possible spit\n",
        "        for split in possible_splits: \n",
        "          left_indices = feature_values <= split # getting indices for left child\n",
        "          right_indices = feature_values > split # getting indices for right child\n",
        "          if np.sum(left_indices) > 0 and np.sum(right_indices) > 0: # checking fot the cornner cases\n",
        "            y_left = y[left_indices]\n",
        "            y_right = y[right_indices]\n",
        "            gain = self._criterion_gain(y, y_left, y_right) # getting criterion gain for the given criterion options are gini entropy misclassification errot\n",
        "            if gain > best_gain:  # getting the best gain and selecting that splits from all the best possible split\n",
        "              best_gain = gain\n",
        "              best_criteria = (feature_idx, split)\n",
        "              best_sets = (left_indices, right_indices)\n",
        "      if best_gain > 0.0: # if some gain than take the left anf right child\n",
        "        left = self.grow_decission_tree(X[best_sets[0]], y[best_sets[0]], depth + 1)  # grow left tree\n",
        "        right = self.grow_decission_tree(X[best_sets[1]], y[best_sets[1]], depth + 1) # grow right tree\n",
        "        node.set_params(best_criteria[0],best_criteria[1]) # setting parameters\n",
        "        node.set_children(left,right) # setting children \n",
        "        node.num_samples = None\n",
        "      else:\n",
        "        node.is_leaf = True # its the leaf tree\n",
        "        node.set_children(None,None)\n",
        "    return node\n",
        "\n",
        "  def split_the_data(self, feature_array):\n",
        "    \"\"\"This is a Python function that splits an input feature array into intervals. It first finds the unique values in the feature array using NumPy. If there is only one unique value, it returns an empty list. If there are multiple unique values, the function calculates the midpoints between consecutive values by taking the average of each value with the next value in the sorted list of unique values\n",
        "    \"\"\"\n",
        "    data = np.unique(feature_array)\n",
        "    if len(data) == 1:\n",
        "        return [] \n",
        "    mp = (data[:-1] + data[1:]) / 2\n",
        "    return mp\n",
        "\n",
        "  def _criterion_gain(self, y, y_left, y_right):\n",
        "    \"\"\"\n",
        "    Common function for all criterian\"\"\"\n",
        "    parent_score = self.criterion_function(y)\n",
        "    left_score = self.criterion_function(y_left)\n",
        "    right_score = self.criterion_function(y_right)\n",
        "    fl = y_left.size / y.size\n",
        "    fr = y_right.size / y.size\n",
        "    gain = parent_score - (fl * left_score + fr * right_score)\n",
        "    return gain\n",
        "\n",
        "  def criterion_function(self, y):\n",
        "    \"\"\"This function calculates the criterion score for a dataset based on a specified criterion, which can be 'gini', 'entropy', or 'misclassification error'.\n",
        "    It takes one input array y representing the target variable and returns the calculated score.\"\"\"\n",
        "    if self.criterion == 'gini':\n",
        "      _, l = np.unique(y, return_counts=True)\n",
        "      probs = l / y.size\n",
        "      cal_score = 1.0 - np.sum(probs ** 2)\n",
        "    elif self.criterion == 'entropy':\n",
        "      _, l = np.unique(y, return_counts=True)\n",
        "      probs = l / y.size\n",
        "      cal_score = -np.sum(probs * np.log2(probs))\n",
        "    elif self.criterion == 'misclassification error':\n",
        "      _, l = np.unique(y, return_counts=True)\n",
        "      probs = l / y.size\n",
        "      cal_score = 1.0 - np.max(probs)\n",
        "    else:\n",
        "        raise ValueError(\"No Allowed values: 'gini', 'entropy', 'misclassification error' is passed.\")\n",
        "    return cal_score\n",
        "  \n",
        "  def predict(self, X):\n",
        "    \"\"\"This function makes predictions using a trained decision tree on new data. It takes an input feature matrix `X`, \n",
        "    uses a for loop to traverse each sample, and returns an array of predicted class labels for each sample in `X`.\"\"\"\n",
        "    n_samples = X.shape[0]\n",
        "    y_pred = np.zeros((n_samples,))\n",
        "    for i in range(n_samples): # Traversing the whole tree\n",
        "      node = self.root\n",
        "      while not node.is_leaf:\n",
        "        if node.split is not None: # for corner case if no split possible\n",
        "          if X[i][node.feature_idx] <= node.split:\n",
        "            node = node.left\n",
        "          else:\n",
        "            node = node.right\n",
        "        else:\n",
        "          break\n",
        "      y_pred[i] = node.predicted_class\n",
        "    return y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 602,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfrV4Koedkiy",
        "outputId": "32360312-7a0e-493f-d6a0-dfed69814a4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.8619528619528619\n",
            "Predicted Class Label: [0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0.\n",
            " 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
            " 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
            " 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 1. 1. 1. 0. 0. 1. 0. 0. 1.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# create a decision tree and fit it to the data\n",
        "tree = DecissionTree(criterion='gini', max_depth=6 , min_samples_split=2, min_samples_leaf=1)\n",
        "tree.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = tree.predict(x_train)\n",
        "accuracy = np.mean(y_pred == y_train)\n",
        "\n",
        "print('Training Accuracy:', accuracy)\n",
        "y_pred = tree.predict(x_test)\n",
        "print(\"Predicted Class Label:\", y_pred)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 603,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "class RandomForest:\n",
        "    \"\"\"\n",
        "    for replacement and extracting features \n",
        "    https://towardsdatascience.com/understanding-sampling-with-and-without-replacement-python-7aff8f47ebe4\n",
        "    for random sampling\n",
        "    https://pynative.com/python-random-sample/\n",
        "    use of max for most common\n",
        "    https://www.geeksforgeeks.org/python-max-function/\n",
        "    \"\"\"\n",
        "    def __init__(self, classifier, num_trees, min_features):\n",
        "        \"\"\"\n",
        "        classifier - decission tree object\n",
        "        num_trees - No. of trees.\n",
        "        min_features - Minimum features to take.\n",
        "        \"\"\"\n",
        "        self.classifier = classifier\n",
        "        self.num_trees = num_trees\n",
        "        self.min_features = min_features\n",
        "        self.feature_indices = None # to store randomly selected features\n",
        "    def sample_with_replacement(self,X):\n",
        "        return [random.randint(0, len(X)-1) for _ in range(len(X))] # Replacing randome\n",
        "    def random_subset_feature(self,nf):\n",
        "        return random.sample(range(nf), random.randint(self.min_features, nf)) # choosing random no. of features ranging from min_features to total no. of features\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Making n trees, selecting sample with replacement and taking random feature subser=t\n",
        "        \"\"\"\n",
        "        # Create num_trees decision trees\n",
        "        self.trees = []\n",
        "        for _ in range(self.num_trees): # making n no. of trees\n",
        "            random.seed(123)\n",
        "            sample_indices = self.sample_with_replacement(X) # Sample with replacement\n",
        "            data = X[sample_indices] # get data\n",
        "            class_pred = y[sample_indices] # getting y values after replacement\n",
        "\n",
        "            feature_indices = self.random_subset_feature(X.shape[1])  # Select a random subset of features\n",
        "            self.feature_indices = feature_indices\n",
        "            data = data[:, feature_indices] # get data after random selecting\n",
        "\n",
        "            tree = self.classifier # Fit a decision tree using the sample and feature subset\n",
        "            tree.fit(data, class_pred)\n",
        "            self.trees.append(tree) # append object of tree after training\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Getting most common from all trees\"\"\"\n",
        "        predictions = self.get_predictions_from_tree(X)\n",
        "        # Find the most common prediction for each sample\n",
        "        y_pred = []\n",
        "        for i in range(len(X)):\n",
        "            sample_predictions = [pred[i] for pred in predictions]\n",
        "            most_common = max(set(sample_predictions), key=sample_predictions.count)\n",
        "            y_pred.append(most_common)\n",
        "        return y_pred\n",
        "    \n",
        "    def get_predictions_from_tree(self,X):\n",
        "        \"\"\"\n",
        "        Get predictions from All trees\"\"\"\n",
        "        predictions = []\n",
        "        for tree in self.trees:\n",
        "            predictions.append(tree.predict(X))\n",
        "        return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 604,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.3153759820426487\n",
            "Predicted Class Label: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForest(DecissionTree(criterion='entropy', max_depth=6, min_samples_split=2, min_samples_leaf=1), num_trees=5, min_features=4)\n",
        "rf.fit(x_train,y_train)\n",
        "y_pred = rf.predict(x_train)\n",
        "accuracy = np.mean(y_pred == y_train)\n",
        "\n",
        "print('Training Accuracy:', accuracy)\n",
        "y_pred = rf.predict(x_test)\n",
        "print(\"Predicted Class Label:\", y_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 605,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AdaBoost:\n",
        "    def __init__(self, weak_learner, num_learners, learning_rate):\n",
        "        self.weak_learner = weak_learner\n",
        "        self.num_learners = num_learners\n",
        "        self.learning_rate = learning_rate\n",
        "        self.learners = []\n",
        "        self.weights = []\n",
        "    def initializing_the_weights(self,n):\n",
        "        \"\"\"\n",
        "        initializing weight\n",
        "        \"\"\"\n",
        "        gen_weights = np.full(n, 1/n)\n",
        "        return gen_weights\n",
        "    def fit(self, X, y):\n",
        "        self.weights = self.initializing_the_weights(X.shape[0]) # Initialize weights\n",
        "\n",
        "        for i in range(self.num_learners):\n",
        "            # Weight training data by sample weights\n",
        "            # print(f\"x={X.shape},w={self.weights.shape}\")\n",
        "            reshape_weight_array= np.array(self.weights).reshape(-1, 1) #reshaping for manage shape\n",
        "            weighted_X = np.multiply(X, reshape_weight_array) #calculated weighted array \n",
        "            # print(f\"y={y.shape},wx={weighted_X.shape}\")\n",
        "            learner = self.weak_learner.fit(weighted_X, y) # Train weak learner (Decission tree) on weighted data\n",
        "            y_pred = learner.predict(X) # Predict on training data\n",
        "            incorrect = [1 if y_pred[i] != y[i] else 0 for i in range(len(y))] \n",
        "            weighted_error = sum([w * incorrect[i] for i, w in enumerate(self.weights)]) / sum(self.weights) # and calculate error\n",
        "\n",
        "            if weighted_error == 0:\n",
        "                learner_weight = float('inf')\n",
        "            else:\n",
        "                learner_weight = np.log((1 - weighted_error) / weighted_error) * self.learning_rate\n",
        "            exponent = np.multiply(y, y_pred)\n",
        "            self.weights *= np.exp(-learner_weight * np.where(exponent < 0, 1, 0))\n",
        "\n",
        "            self.learners.append(learner)\n",
        "            self.weights /= np.sum(self.weights) # add weights\n",
        "\n",
        "            if weighted_error == 0: # stoppoing early if no error change\n",
        "                break\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Predict using weighted ensemble of learners\n",
        "        # print(f\"x={X.shape},w={self.weights.shape}\")\n",
        "        learner_preds = [learner.predict(X) for learner in self.learners]\n",
        "\n",
        "        weights = np.tile(np.array(self.weights)[:, np.newaxis], (1, len(self.learners)))\n",
        "        # print(f\"x={np.array(learner_preds).shape},w={weights.shape}\")\n",
        "        learner_preds_trans = np.array(learner_preds).T\n",
        "        ensemble_pred = np.sign(np.sum(weights * learner_preds_trans, axis=1))\n",
        "        return ensemble_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 606,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.24242424242424243\n",
            "Predicted Class Label: [1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0.\n",
            " 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0.\n",
            " 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.\n",
            " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
            " 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0.\n",
            " 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0.\n",
            " 0. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "# Create AdaBoost classifier with DecisionTree weak learner\n",
        "adaboost = AdaBoost(weak_learner=DecissionTree(criterion='misclassification error', max_depth=18, min_samples_split=2, min_samples_leaf=1),\n",
        "                    num_learners=50,\n",
        "                    learning_rate=0.1)\n",
        "\n",
        "# Train AdaBoost classifier on training data\n",
        "adaboost.fit(adaboost_x_train, adaboost_y_train)\n",
        "y_pred = adaboost.predict(adaboost_x_train)\n",
        "accuracy = np.mean(y_pred == adaboost_y_train)\n",
        "\n",
        "print('Training Accuracy:', accuracy)\n",
        "y_pred = adaboost.predict(adaboost_x_train)\n",
        "print(\"Predicted Class Label:\", y_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Accuracy "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Model | Accuracy(%) |\n",
        "| --- | ----------- |\n",
        "| Decission Tree | 83.05274971941639% |\n",
        "| Random Forest | 40.62401795735129% |\n",
        "| Adaboost | 24.464646464646464% |"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
